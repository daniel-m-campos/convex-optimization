{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse as spr\n",
    "from scipy import special\n",
    "\n",
    "np.random.seed(1)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Maximum likelihood prediction of team ability\n",
    "A set of $n$ teams compete in a tournament. We model each team's ability by a number  $a_j \\in [0,1]$,  $j=1,\\ldots, n$ . When teams $j$ and $k$ play each other, the probability that team $j$ wins is equal to $\\mathbf{prob}(a_j-a_k+v>0)$, where $v \\sim \\mathcal N(0,\\sigma^2)$.\n",
    "\n",
    "You are given the outcome of $m$ past games. These are organized as\n",
    "\n",
    "$$\n",
    "(j^{(i)},k^{(i)},y^{(i)}), \\quad i = 1,\\ldots,m,\n",
    "$$\n",
    "\n",
    "meaning that game $i$ was played between teams $j^{(i)}$ and $k^{(i)}$; $y^{(i)}=1$ means that team $j^{(i)}$ won, while $y^{(i)}=-1$ means that team $k^{(i)}$ won. (We assume there are no ties.)\n",
    "\n",
    "Formulate the problem of finding the maximum likelihood estimate of team abilities, $\\hat a \\in \\mathbf{R}^n$, given the outcomes, as a convex optimization problem. You will find the *game incidence matrix* $A\\in \\mathbf{R}^{m \\times n}$, defined as\n",
    "\n",
    "$$\n",
    "A_{il} = \\left\\{\\begin{array}{rl}y^{(i)} & l = j^{(i)}\\\\-y^{(i)} & l = k^{(i)}\\\\0 & \\mbox{otherwise},\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "useful.\n",
    "\n",
    "The prior constraints $\\hat a_i \\in [0,1]$ should be included in the problem formulation. Also, we note that if a constant is added to all team abilities, there is no change in the probabilities of game outcomes. This means that  ð‘ŽÌ‚   is determined only up to a constant, like a potential. But this doesn't affect the ML estimation problem, or any subsequent predictions made using the estimated parameters.\n",
    "\n",
    "Find $\\hat a$ for the team data given in `team_data.m`, in the matrix train. (This matrix gives the outcomes for a tournament in which each team plays each other team once.) You may find the CVX function `log_normcdf` helpful for this problem.\n",
    "\n",
    "You can form $A$ using the commands\n",
    "```\n",
    "A = sparse(1:m,train(:,1),train(:,3),m,n) + ...\n",
    "    sparse(1:m,train(:,2),-train(:,3),m,n);\n",
    "```\n",
    "Finally, use the maximum likelihood estimate  ð‘ŽÌ‚   to predict the outcomes of next year's tournament games, given in the matrix test, using $\\hat y^{(i)} = \\mathbf{sign}(\\hat a_{j^{(i)}} - \\hat a_{k^{(i)}})$. Compare these predictions with the actual outcomes, given in the third column of test. What is the fraction of correctly predicted outcomes? (If half of the outcomes are correctly predicted, the answer is 0.5 and not 50.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "First, we need to construct the likelihood function. For the observed data, we know that $a_j-a_k +v \\sim \\mathcal{N}(a_j-a_k, \\sigma^2)$ and that $y\\cdot(a_j-a_k +v) > 0$, this implies that:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{P}(y=1) &= \\mathbb{P}(a_{j^{(i)}}-a_{k^{(i)}} + v > 0) \\\\\n",
    "&= 1 - \\Phi\\left(\\frac{0-(a_{j^{(i)}}-a_{k^{(i)}})} {\\sigma}\\right) \\\\\n",
    "&= \\Phi\\left(\\frac{a_{j^{(i)}}-a_{k^{(i)}}} {\\sigma}\\right) \\\\\n",
    "\\mathbb{P}(y=-1) &= \\mathbb{P}(a_{j^{(i)}}-a_{k^{(i)}} + v < 0) \\\\\n",
    "&= \\Phi\\left(\\frac{0-(a_{j^{(i)}}-a_{k^{(i)}})} {\\sigma}\\right) \\\\\n",
    "&= \\Phi\\left(\\frac{-(a_{j^{(i)}}-a_{k^{(i)}})} {\\sigma}\\right) \n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\boxed{\\therefore \\mathbb{P}(y=y_i) = \\Phi\\left(\\frac{y_i\\cdot(a_{j^{(i)}}-a_{k^{(i)}})} {\\sigma}\\right) }\n",
    "$$\n",
    "\n",
    "Thus the likelihood function is:\n",
    "$$\n",
    "p_a(y) = \\prod_{i=1}^m  \\Phi\\left(\\frac{y^{(i)}\\cdot(a_{j^{(i)}}-a_{k^{(i)}})} {\\sigma} \\right)\n",
    "$$\n",
    "Which gives the log-likelihood:\n",
    "$$\n",
    "\\boxed{l(a, y) = \\sum_{i=1}^m \\ln\\left(\\Phi\\left(\\frac{y^{(i)}\\cdot(a_{j^{(i)}}-a_{k^{(i)}})} {\\sigma}\\right)\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_game_incidence_matrix(data, num_teams):\n",
    "    num_games = data.shape[0]\n",
    "    gim = np.zeros((num_games, num_teams))\n",
    "    for p, r in enumerate(data):\n",
    "        j, k, y = r\n",
    "        gim[p, j - 1] = y\n",
    "        gim[p, k - 1] = -y\n",
    "    gim_sp = spr.csc_matrix(gim)\n",
    "    return gim_sp\n",
    "\n",
    "\n",
    "def get_team_data():\n",
    "    n = 10\n",
    "    m = 45\n",
    "    m_test = 45\n",
    "    sigma = 0.250\n",
    "    train = np.array(\n",
    "        [\n",
    "            [1, 2, 1],\n",
    "            [1, 3, 1],\n",
    "            [1, 4, 1],\n",
    "            [1, 5, 1],\n",
    "            [1, 6, 1],\n",
    "            [1, 7, 1],\n",
    "            [1, 8, 1],\n",
    "            [1, 9, 1],\n",
    "            [1, 10, 1],\n",
    "            [2, 3, -1],\n",
    "            [2, 4, -1],\n",
    "            [2, 5, -1],\n",
    "            [2, 6, -1],\n",
    "            [2, 7, -1],\n",
    "            [2, 8, -1],\n",
    "            [2, 9, -1],\n",
    "            [2, 10, -1],\n",
    "            [3, 4, 1],\n",
    "            [3, 5, -1],\n",
    "            [3, 6, -1],\n",
    "            [3, 7, 1],\n",
    "            [3, 8, 1],\n",
    "            [3, 9, 1],\n",
    "            [3, 10, 1],\n",
    "            [4, 5, -1],\n",
    "            [4, 6, -1],\n",
    "            [4, 7, 1],\n",
    "            [4, 8, 1],\n",
    "            [4, 9, -1],\n",
    "            [4, 10, -1],\n",
    "            [5, 6, 1],\n",
    "            [5, 7, 1],\n",
    "            [5, 8, 1],\n",
    "            [5, 9, -1],\n",
    "            [5, 10, 1],\n",
    "            [6, 7, 1],\n",
    "            [6, 8, 1],\n",
    "            [6, 9, -1],\n",
    "            [6, 10, -1],\n",
    "            [7, 8, 1],\n",
    "            [7, 9, 1],\n",
    "            [7, 10, -1],\n",
    "            [8, 9, -1],\n",
    "            [8, 10, -1],\n",
    "            [9, 10, 1],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test = np.array(\n",
    "        [\n",
    "            [1, 2, 1],\n",
    "            [1, 3, 1],\n",
    "            [1, 4, 1],\n",
    "            [1, 5, 1],\n",
    "            [1, 6, 1],\n",
    "            [1, 7, 1],\n",
    "            [1, 8, 1],\n",
    "            [1, 9, 1],\n",
    "            [1, 10, 1],\n",
    "            [2, 3, -1],\n",
    "            [2, 4, 1],\n",
    "            [2, 5, -1],\n",
    "            [2, 6, -1],\n",
    "            [2, 7, -1],\n",
    "            [2, 8, 1],\n",
    "            [2, 9, -1],\n",
    "            [2, 10, -1],\n",
    "            [3, 4, 1],\n",
    "            [3, 5, -1],\n",
    "            [3, 6, 1],\n",
    "            [3, 7, 1],\n",
    "            [3, 8, 1],\n",
    "            [3, 9, -1],\n",
    "            [3, 10, 1],\n",
    "            [4, 5, -1],\n",
    "            [4, 6, -1],\n",
    "            [4, 7, -1],\n",
    "            [4, 8, 1],\n",
    "            [4, 9, -1],\n",
    "            [4, 10, -1],\n",
    "            [5, 6, -1],\n",
    "            [5, 7, 1],\n",
    "            [5, 8, 1],\n",
    "            [5, 9, 1],\n",
    "            [5, 10, 1],\n",
    "            [6, 7, 1],\n",
    "            [6, 8, 1],\n",
    "            [6, 9, 1],\n",
    "            [6, 10, 1],\n",
    "            [7, 8, 1],\n",
    "            [7, 9, -1],\n",
    "            [7, 10, 1],\n",
    "            [8, 9, -1],\n",
    "            [8, 10, -1],\n",
    "            [9, 10, 1],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    A_train = create_game_incidence_matrix(train, n)\n",
    "    A_test = create_game_incidence_matrix(test, n)\n",
    "    return n, m, sigma, m_test, train, test, A_train, A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, sigma, m_test, train, test, A_train, A_test = get_team_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvx_log_noramcdf(x: cp.Variable):\n",
    "    cdf = 0.5 * (1 + np.erf(x_))\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Approximation of `erf`\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname {erf} (x) &={\\begin{cases}1-\\tau &x\\geq 0\\\\\\tau -1&x<0\\end{cases}} \\\\\n",
    "\\tau &:=t\\cdot \\exp \\left(-x^{2}-1.26551223+1.00002368t+0.37409196t^{2}+0.09678418t^{3}-0.18628806t^{4}\\right.\\\\\n",
    "&\\left.\\qquad \\qquad \\qquad +0.27886807t^{5}-1.13520398t^{6}+1.48851587t^{7}-0.82215223t^{8}+0.17087277t^{9}\\right) \\\\\n",
    "t&:={\\frac {1}{1+0.5|x|}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_normcdf is not in cvxpy and not trivial to supprt it.\n",
    "def erf(x):\n",
    "    coefs = (\n",
    "        -1.26551223,\n",
    "        1.00002368,\n",
    "        0.37409196,\n",
    "        0.09678418,\n",
    "        -0.18628806,\n",
    "        0.27886807,\n",
    "        -1.13520398,\n",
    "        1.48851587,\n",
    "        -0.82215223,\n",
    "        0.17087277,\n",
    "    )\n",
    "    t = 1 / (1 + cp.abs(x) / 2)\n",
    "    Ï„ = cp.multiply(\n",
    "        t,\n",
    "        cp.exp(\n",
    "            -cp.power(x, 2)\n",
    "            + cp.sum(\n",
    "                [cp.multiply(coef, cp.power(t, p)) for p, coef in enumerate(coefs)]\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    return 1 - Ï„  # if x >= 0 else Ï„ - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cp.Variable(n)\n",
    "z = A_train @ a / sigma / np.sqrt(2)\n",
    "constraints = [a >= 0, a <= 1]\n",
    "obj = cp.Maximize(cp.sum(cp.log((1 + erf(z)) / 2)))\n",
    "prob = cp.Problem(obj, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Allocation of interdiction effort\n",
    "A smuggler moves along a directed acyclic graph with $m$ edges and $m$ nodes, from a source node (which we take as node  1) to a destination node (which we take as node $n$), along some (directed) path. Each edge $k$ has a detection failure probability $p_k$, which is the probability that the smuggler passes over that edge undetected. The detection events on the edges are independent, so the probability that the smuggler makes it to the destination node undetected is $\\prod_{j \\in \\mathcal P} p_j$, where $\\mathcal P~\\subset~\\{1,\\ldots, m\\}$ is (the set of edges on) the smuggler's path. We assume that the smuggler knows the detection failure probabilities and will take a path that maximizes the probability of making it to the destination node undetected. We let $P^\\max$ denote this maximum probability (over paths). (Note that this is a function of the edge detection failure probabilities.)\n",
    "\n",
    "The edge detection failure probability on an edge depends on how much interdiction resources are allocated to the edge. Here we will use a very simple model, with $x_j \\in \\mathbf{R}_+$ denoting the effort (say, yearly budget) allocated to edge $j$, with associated detection failure probability $p_j = e^{-a_j x_j}$, where $a_j \\in \\mathbf{R}_{++}$ are given. The constraints on $x$ are a maximum for each edge, $x \\preceq x^\\mathrm{max}$, and a total budget constraint, $\\mathbf{1}^Tx \\leq B$.\n",
    "\n",
    "Pose the problem of choosing the interdiction effort vector $x \\in \\mathbf{R}^m$ that minimizes $P^\\max$, subject to the constraints, as a convex optimization problem. Your formulation should not enumerate all possible paths (in the objective or constraints). Hint. For each node $i$, let $P_i$ denote the maximum of $\\prod_{k\\in \\mathcal P}p_k$ over all paths $\\mathcal P$ from the source node 1 to node $i$ (so $P^\\max = P_n$).\n",
    "\n",
    "Carry out your method on the problem instance given in `interdict_alloc_data.m`. The data file contains the data  $a,x^\\max,B$, and the graph incidence matrix $A \\in \\mathbf{R}^{n \\times m}$, where\n",
    "\n",
    "$$\n",
    "A_{ij} = \\left\\{ \\begin{array}{ll} -1 & \\mbox{if edge \\(j\\) leaves node \\(i\\)}\\\\+1 & \\mbox{if edge \\(j\\) enters node \\(i\\)}\\\\0 & \\mbox{otherwise}. \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Give $P^{\\mathrm{max}\\star}$, the optimal value of $P^\\max$, and compare it to the value of $p^\\max$ obtained with uniform allocation of resources, i.e., with $x= (B/m) \\mathbf{1}$.\n",
    "\n",
    "Hint. Given a vector $z \\in \\mathbf{R}^n$, $A^T z$ is the vector of edge differences: $(A^Tz)_j = z_k - z_l$ if edge $j$ goes from node $l$ to node $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the value of $P^{\\max\\star}$? (Write 0.1 for 10%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interdict_alloc_data():\n",
    "    np.random.seed(0)\n",
    "    n, m = 10, 20\n",
    "    edges = [\n",
    "        (0, 1),\n",
    "        (0, 2),\n",
    "        (0, 3),\n",
    "        (1, 2),\n",
    "        (1, 3),\n",
    "        (1, 5),\n",
    "        (2, 4),\n",
    "        (2, 5),\n",
    "        (3, 5),\n",
    "        (3, 6),\n",
    "        (4, 6),\n",
    "        (4, 7),\n",
    "        (5, 6),\n",
    "        (5, 7),\n",
    "        (6, 7),\n",
    "        (6, 8),\n",
    "        (6, 9),\n",
    "        (7, 8),\n",
    "        (7, 9),\n",
    "        (8, 9),\n",
    "    ]\n",
    "    a = 2 * np.random.rand(m)\n",
    "    x_max = 1 + np.random.rand(m)\n",
    "    B = m / 2.0\n",
    "    A = np.zeros((n, m))\n",
    "    for k, (i, j) in enumerate(edges):\n",
    "        A[i, k] = -1\n",
    "        A[j, k] = 1\n",
    "    return n, m, a, x_max, B, edges, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not equal to MATLAB generated data due to difference in RNGs.\n",
    "n, m, a, x_max, B, edges, A = get_interdict_alloc_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the value of $P^\\max$ obtained with uniform allocation of resources? (Write 0.1 for 10%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cp.Variable(m, nonneg=True)\n",
    "z = cp.Variable(n)\n",
    "\n",
    "obj = cp.Minimize(z[-1])\n",
    "constraints = [z[0] == 0, A.T @ z >= -cp.diag(a) @ x, x <= x_max, cp.sum(x) <= B]\n",
    "\n",
    "prob = cp.Problem(obj, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9116454040875612"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = prob.solve()\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054386168982720653"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_max = np.exp(opt)\n",
    "P_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the value of $P^\\max$ obtained with uniform allocation of resources? (Write 0.1 for 10%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_unifrom = cp.Problem(prob.objective, constraints + [x == B / m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36552401686307545"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_unifrom = prob_unifrom.solve()\n",
    "P_max_uniform = np.exp(opt_unifrom)\n",
    "P_max_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
